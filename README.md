# NISCA

NISCA is a deep generative modeling framework for unsupervised latent source separation in spectral imaging data, with applications in remote sensing, medical imaging, astrophysics, and finance.
It extends traditional variational autoencoder architecture with the domain-specific inductive bias, by using geometrically constrained simplex priors, enabling interpretable and identifiable latent representations under noisy nonlinear mixing.
A scalable production-grade implementation is provided, along with exhaustive documentation, and demonstration notebooks.
The project supports datasets from hyperspectral satellite images, dynamic contrast-enhanced (DCE) MRI scans, and synthetic simulations.

[//]: # (geometric priors &#40;e.g., Dirichlet&#41; and nonlinear decoders, 
 even in complex post-nonlinear mixtures.)
[//]: # ( tissue and material separation from high-dimensional imaging data, including hyperspectral satellite images and dynamic contrast-enhanced &#40;DCE&#41; MRI scans)

### Highlights

[//]: # (- Bayesian inference via deep variational autoencoders)

[//]: # (- Geometrically constrained latent space &#40;e.g., simplex priors&#41; suitable for categorical ground truth)

[//]: # (- Post-nonlinear decoder architecture)

[//]: # (- Theoretical identifiability under nonlinear mixing)

[//]: # (- Synthetic and real-world datasets &#40;hyperspectral, DCE-MRI&#41;)

[//]: # (- Comprehensive experiment tracking with Weights & Biases)

[//]: # (- Efficient implementation compatible with high-performance computing using CUDA)

[//]: # (- Modular and scalable PyTorch Lightning pipeline)

[//]: # (- Integrated support for GCP/Docker)

[//]: # (The code implements the NISCA algorithm for training VAEs on imaging data using the PyTorch Lightning framework, as well benchmarking against linear baselines, and nonlinear benchmark. The code is modular and designed for scalability, allowing for easy experimentation with different model architectures and configurations.)

[//]: # (It supports both hyperspectral and medical data formats, includes synthetic simulation pipelines, and uses structured experiment tracking.)

[//]: # ()
[//]: # (The core codebase includes:)

[//]: # (- Modular PyTorch Lightning modules for training, evaluation, and logging)

[//]: # (- Configurable architecture for encoder, decoder, and latent space)

[//]: # (- Experiment tracking via Weights & Biases &#40;W&B&#41;)

[//]: # (- Dockerized environment for reproducibility)


- **Variational autoencoders** with simplex-constrained latent priors (Dirichlet, Logistic-Normal)
- **Post-nonlinear decoder** supporting arbitrary invertible transforms
- **Synthetic + real-world** data support (Urban, Cuprite, MRI, financial datasets)
- **Augmented Lagrangian optimization** for constrained training
- **Multi-experiment orchestration**, WandB logging, sweeping, and GCP/Docker compatibility
- **Metrics for identifiability and recovery**: subspace distance, Amari index, mutual info, etc.

### Technological Stack

- **PyTorch Lightning** for training and evaluation
- **Weights & Biases (W&B)** for logging
- **NumPy**, **Matplotlib**, **Scikit-learn**
- **Docker** + **GCP** compatibility
- **Configurable JSON experiments**
- Optional **CUDA** acceleration

For more information, see Master thesis [manuscript](docs/thesis.pdf), IEEE [preprint](docs/preprint.pdf), and [slides](docs/slides.pdf), or jump to:


[//]: # (- [Highlights]&#40;#highlights&#41;)

- [Installation](#installation)

- [Usage](#usage)

- [Codebase](#codebase)

- [Publication](#publication)

- [Contact](#contact)

- [Contributing](#contributing)

- [License](#license)

## Installation

To clone the repository, run:

```bash
  git clone https://github.com/vladyslav-pauk/nisca.git
```
Install dependencies:
```bash
  pip install -r requirements.txt
```

Set up W&B credentials:
```bash
  wandb login
```


## Usage

### Train a Model

To train a model, run:


```bash
  PYTHONPATH=./ python src/scripts/run_sweep.py --experiment synthetic --sweep test_run
```

This reads configuration from:
- `experiments/simplex_recovery/config/data.json`
- `experiments/simplex_recovery/config/model/nisca.json`

Job results are stored under `experiments/{experiment_name}/config/sweep/`

### Model Evaluation

To analyze the latest sweep, run:

```bash
  PYTHONPATH=./ python src/scripts/analyze_sweep.py --experiment synthetic
```
or pass with `--sweep <sweep_name>` flag to visualize a specific sweep.

To access the latest run results, use:

```bash
  PYTHONPATH=./ python src/scripts/explore_model.py --experiment synthetic
```
or pass with `--run_id <id>` flag to visualize a specific run.

Plots and logs will be saved and logged to W&B under the specified experiment name.

### CUDA

To enable CUDA support, set the environment variable `CUDA_VISIBLE_DEVICES` to the desired GPU ID(s):

```bash
  export CUDA_VISIBLE_DEVICES=0,1
```

### Jupyter Notebooks
The repository includes Jupyter notebooks for interactive exploration of the models and datasets and reproducing results from the paper.

- [**Model Training**](notebooks/model_training.ipynb): Walkthrough of training a model with different configurations.
- [**Training Evaluation**](notebooks/quantitative_evaluation.ipynb): Benchmarking against classic methods and analyzing results.
- [**Synthetic Data**](notebooks/mixture_model.ipynb): Generating and visualizing synthetic data for testing.

You can run them in a Jupyter environment or convert them to scripts using `nbconvert`.

```bash
  jupyter nbconvert --to script notebook.ipynb
```

### Containerization


## Codebase


### Datasets

The framework supports:

- Synthetic mixtures with known ground truth
- Hyperspectral satellite images (Urban, Cuprite, Samson)
- Public DCE-MRI volumes
- Financial and astronomical data

All datasets are configured using `data.json` with preprocessing and loading logic defined in `data/*.py`.

### Models

Implemented models include:

- `nisca`: Nonlinear ICA with simplex prior
- `vasca`: Variational simplex component analysis
- `cnae`: Constrained nonlinear autoencoder
- `nica`: Nonlinear ICA baseline
- `snae`: Simplex autoencoder
- `aevb`: Standard VAE (baseline)

Each model has its own encoder/decoder class under `model/architectures` and a training logic module in `model/modules`.


### Metrics

The following metrics are supported:

- **Reconstruction error** (RMSE)
- **Subspace distance** (Amari distance, spectral angle)
- **Residual nonlinearity**
- **Simplex mismatch**
- **Constraint error**
- **PSNR** and **RÂ²**
- **Separation & identifiability**

All metrics are computed via `model/metric/*.py` and logged to W&B.


### Directory Structure

```
.
â”œâ”€â”€ experiments/              # Experiment folders with data/model config JSON files
â”‚   â””â”€â”€ {experiment}/
â”‚       â””â”€â”€ config/
â”‚           â”œâ”€â”€ data.json
â”‚           â”œâ”€â”€ model/
â”‚           â”‚   â””â”€â”€ {model_name}.json
â”‚           â””â”€â”€ sweep/
â”‚               â””â”€â”€ {sweep_config}.json
â”œâ”€â”€ model/                    # Main model definitions: NISCA, CNAE, VASCA, etc.
â”‚   â”œâ”€â”€ architectures/        # Encoder-decoder variants
â”‚   â”œâ”€â”€ config/               # Default model configuration JSONs
â”‚   â”œâ”€â”€ modules/              # LightningModule wrappers for training
â”‚   â”œâ”€â”€ benchmarks/           # MVES and other classic baselines
â”‚   â””â”€â”€ metric/               # Evaluation metrics (e.g., separation, identifiability)
â”œâ”€â”€ modules/                  # Optimizer and transform libraries
â”‚   â”œâ”€â”€ optimizer/            # Augmented Lagrangian optimizer
â”‚   â”œâ”€â”€ network/              # CNN, FCN, KAN, positive linear layers
â”‚   â””â”€â”€ transform/            # Nonlinear transforms (logit, glogit, etc.)
â”œâ”€â”€ data/                     # Data loaders: MRI, hyperspectral, synthetic, etc.
â”‚   â”œâ”€â”€ {domain}.py           # MRI, hyperspectral, astronomical, EEG, etc.
â”‚   â”œâ”€â”€ *.json                # Dataset configurations
â”‚   â””â”€â”€ plots/                # Diagnostic plots (MRI, tensor slices)
â”œâ”€â”€ scripts/                  # High-level wrappers and analysis tools
â”‚   â”œâ”€â”€ run_dataset.py
â”‚   â”œâ”€â”€ run_sweep.py
â”‚   â”œâ”€â”€ analyze_sweep.py
â”‚   â”œâ”€â”€ explore_model.py
â”‚   â””â”€â”€ compare_models.py
â”œâ”€â”€ helpers/                  # Training entrypoint and sweep orchestration
â”‚   â”œâ”€â”€ trainer.py            # Core train_model() function
â”‚   â”œâ”€â”€ generate_data.py      # Synthetic data simulation
â”‚   â””â”€â”€ sweep_runner.py       # Grid & random search over configs
â”œâ”€â”€ utils/                    # Logging (W&B), metrics, plotting, config parsing
â”‚   â”œâ”€â”€ wandb_tools.py
â”‚   â”œâ”€â”€ plot_tools.py
â”‚   â””â”€â”€ config_tools.py
â””â”€â”€ notebooks/                # Optional Jupyter notebooks for visualization
```



## Publication

- [**Master's Thesis**](https://github.com/vladyslav-pauk/isnmm/blob/master/docs/thesis.pdf): *Deep Generative Modeling for Hyperspectral & Medical Imaging*, Vladyslav Pauk, OSU (2024).
- **IEEE Preprint**: Coming soon, see draft [here](https://github.com/vladyslav-pauk/isnmm/blob/master/docs/preprint.pdf).

BibTeX citation:

```bibtex
@misc{pauk2024generative,
  author = {Vladyslav Pauk},
  title = {Post-Nonlinear Mixture Identification via Variational Auto-Encoding},
  year = {2024},
  note = {Master's Thesis, Oregon State University}
}
```


## Contact

- **Author**: Vladyslav Pauk  
- **Email**: [paukvp@gmail.com](mailto:paukvp@gmail.com)  
- **Website**: [linkedin.com/vladyslav-pauk](https://www.linkedin.com/in/vladyslav-pauk)


## Contributing

Pull requests, feedback, and discussions are welcome. Please submit issues or suggestions via GitHub.


## License

MIT License (see [LICENSE](LICENSE))



[//]: # ()
[//]: # (Root directory structure:)

[//]: # (```)

[//]: # (.)

[//]: # (â”œâ”€â”€ datasets/           # Data loading, preprocessing, simulation)

[//]: # (â”œâ”€â”€ docs/               # Documentation &#40;Markdown&#41;)

[//]: # (â”œâ”€â”€ experiments/        # Experiment config files &#40;JSON&#41;)

[//]: # (â”œâ”€â”€ notebooks/          # Analysis, visualization, diagnostics)

[//]: # (â”œâ”€â”€ src/                # Main source scripts and tools)

[//]: # (```)

[//]: # ()
[//]: # (```)

[//]: # (### Experiment Structure)

[//]: # ()
[//]: # (```text)

[//]: # (.)

[//]: # (â”œâ”€â”€ experiments/                # Experiment configurations)

[//]: # (â”‚   â”œâ”€â”€ vision/)

[//]: # (â”‚   â”‚   â””â”€â”€ config/)

[//]: # (â”‚   â”‚       â”œâ”€â”€ data.json)

[//]: # (â”‚   â”‚       â””â”€â”€ model/)

[//]: # (â”‚   â”‚           â””â”€â”€ aevb.json)

[//]: # (â”‚   â”œâ”€â”€ fin_portfolio_return/)

[//]: # (â”‚   â”‚   â”œâ”€â”€ yahoo.json)

[//]: # (â”‚   â”‚   â””â”€â”€ nisca.json)

[//]: # (â”‚   â””â”€â”€ simplex_recovery/)

[//]: # (â”‚       â””â”€â”€ config/)

[//]: # (â”‚           â”œâ”€â”€ data.json)

[//]: # (â”‚           â”œâ”€â”€ sweep/)

[//]: # (â”‚           â”‚   â”œâ”€â”€ model-param.json)

[//]: # (â”‚           â”‚   â”œâ”€â”€ single_run.json)

[//]: # (â”‚           â”‚   â”œâ”€â”€ model-snr.json)

[//]: # (â”‚           â”‚   â””â”€â”€ model-datasize.json)

[//]: # (â”‚           â””â”€â”€ model/)

[//]: # (â”‚               â”œâ”€â”€ nisca.json)

[//]: # (â”‚               â””â”€â”€ vasca.json)

[//]: # (â”œâ”€â”€ wandb/                     # Weights & Biases run logs)

[//]: # (â”‚   â””â”€â”€ run-*/                 # Each run with logs, files, and metadata)

[//]: # (â”‚       â”œâ”€â”€ logs/)

[//]: # (â”‚       â”œâ”€â”€ files/)

[//]: # (â”‚       â””â”€â”€ tmp/)

[//]: # (```)

[//]: # ()
[//]: # (Source code structure:)

[//]: # (```)

[//]: # (â”œâ”€â”€ src/                       # Main source scripts and tools)

[//]: # (â”‚   â”œâ”€â”€ data_module.py)

[//]: # (â”‚   â”œâ”€â”€ metrics_module.py)

[//]: # (â”‚   â”œâ”€â”€ evaluate.py)

[//]: # (â”‚   â”œâ”€â”€ schedule.py)

[//]: # (â”‚   â”œâ”€â”€ SPA.py)

[//]: # (â”‚   â””â”€â”€ test_prism.py)

[//]: # (â”œâ”€â”€ experiments/               # Experiment drivers)

[//]: # (â”‚   â”œâ”€â”€ hyperspectral.py)

[//]: # (â”‚   â”œâ”€â”€ mri.py)

[//]: # (â”‚   â”œâ”€â”€ synthetic.py)

[//]: # (â”‚   â””â”€â”€ portfolio.py)

[//]: # (â”œâ”€â”€ utils/                     # Utilities &#40;logging, config, matrix ops&#41;)

[//]: # (â”‚   â”œâ”€â”€ config_tools.py)

[//]: # (â”‚   â”œâ”€â”€ wandb_tools.py)

[//]: # (â”‚   â”œâ”€â”€ matrix_tools.py)

[//]: # (â”‚   â”œâ”€â”€ plot_tools.py)

[//]: # (â”‚   â””â”€â”€ utils.py)

[//]: # (â”œâ”€â”€ image_marker/              # MRI marker web tool &#40;Flask-based&#41;)

[//]: # (â”‚   â”œâ”€â”€ app.py)

[//]: # (â”‚   â”œâ”€â”€ marked_pixels.mat)

[//]: # (â”‚   â””â”€â”€ templates/)

[//]: # (â”‚       â””â”€â”€ index.html)

[//]: # (â”œâ”€â”€ scripts/                   # Scripts for sweeping, evaluation, etc.)

[//]: # (â”‚   â”œâ”€â”€ run_sweep.py)

[//]: # (â”‚   â”œâ”€â”€ analyze_sweep.py)

[//]: # (â”‚   â”œâ”€â”€ explore_model.py)

[//]: # (â”‚   â”œâ”€â”€ compare_models.py)

[//]: # (â”‚   â””â”€â”€ abundance_classifier.py)

[//]: # (â”œâ”€â”€ model/                     # Model architectures and configs)

[//]: # (â”‚   â”œâ”€â”€ config/)

[//]: # (â”‚   â”‚   â”œâ”€â”€ snae.json)

[//]: # (â”‚   â”‚   â”œâ”€â”€ nisca.json)

[//]: # (â”‚   â”‚   â””â”€â”€ vasca.json)

[//]: # (â”‚   â”œâ”€â”€ architectures/)

[//]: # (â”‚   â”‚   â”œâ”€â”€ aevb.py)

[//]: # (â”‚   â”‚   â”œâ”€â”€ vasca.py)

[//]: # (â”‚   â”‚   â””â”€â”€ nisca.py)

[//]: # (â”‚   â”œâ”€â”€ modules/)

[//]: # (â”‚   â”‚   â”œâ”€â”€ lightning.py)

[//]: # (â”‚   â”‚   â”œâ”€â”€ ae.py)

[//]: # (â”‚   â”‚   â””â”€â”€ vae.py)

[//]: # (â”‚   â””â”€â”€ benchmarks/)

[//]: # (â”‚       â””â”€â”€ mves.py)

[//]: # (â”œâ”€â”€ modules/                   # Modular components &#40;networks, metrics, optimizers&#41;)

[//]: # (â”‚   â”œâ”€â”€ optimizer/)

[//]: # (â”‚   â”‚   â””â”€â”€ augmented_lagrange.py)

[//]: # (â”‚   â”œâ”€â”€ network/)

[//]: # (â”‚   â”‚   â”œâ”€â”€ fcn_constructor.py)

[//]: # (â”‚   â”‚   â”œâ”€â”€ linear_positive.py)

[//]: # (â”‚   â”‚   â””â”€â”€ vision.py)

[//]: # (â”‚   â”œâ”€â”€ metric/)

[//]: # (â”‚   â”‚   â”œâ”€â”€ separation.py)

[//]: # (â”‚   â”‚   â”œâ”€â”€ subspace_distance.py)

[//]: # (â”‚   â”‚   â””â”€â”€ residual_nonlinearity.py)

[//]: # (â”‚   â”œâ”€â”€ distribution/)

[//]: # (â”‚   â”‚   â”œâ”€â”€ standard.py)

[//]: # (â”‚   â”‚   â”œâ”€â”€ mixture_model.py)

[//]: # (â”‚   â”‚   â””â”€â”€ location_scale.py)

[//]: # (â”‚   â”œâ”€â”€ data/)

[//]: # (â”‚   â”‚   â”œâ”€â”€ hyperspectral.py)

[//]: # (â”‚   â”‚   â”œâ”€â”€ dce_mri.py)

[//]: # (â”‚   â”‚   â””â”€â”€ synthetic.py)

[//]: # (â”‚   â””â”€â”€ transform/)

[//]: # (â”‚       â”œâ”€â”€ logit_transform.py)

[//]: # (â”‚       â”œâ”€â”€ glogit_transform.py)

[//]: # (â”‚       â””â”€â”€ nonlinear_component_wise.py)

[//]: # (â”œâ”€â”€ helpers/                   # Sweep & training helpers)

[//]: # (â”‚   â”œâ”€â”€ generate_data.py)

[//]: # (â”‚   â”œâ”€â”€ sweep_analyzer.py)

[//]: # (â”‚   â””â”€â”€ trainer.py)

[//]: # (```)

[//]: # ()
[//]: # (---)

[//]: # ()
[//]: # (## Installation)

[//]: # ()
[//]: # (### Requirements)

[//]: # ()
[//]: # (...)

[//]: # ()
[//]: # (## ğŸ§ª Usage)

[//]: # ()
[//]: # (### Notebooks)

[//]: # ()
[//]: # (Explore interactive Jupyter notebooks covering a range of topics from training to model evaluation and visualization, as well as some experiments.)

[//]: # (- Model training walkthrough)

[//]: # (- Posterior sampling and latent space visualization)

[//]: # (- Component-wise reconstruction)

[//]: # (- Quantitative evaluation and benchmark comparisons)

[//]: # ()
[//]: # (### Training Module)

[//]: # (Run train.py to train a model with a specific config file.)

[//]: # (```bash)

[//]: # (python train.py --config experiments/{experiment_name}/model_config.json)

[//]: # (```)

[//]: # ()
[//]: # (### Scripts)

[//]: # ()
[//]: # (Run a hyperparameter sweep:)

[//]: # (```bash)

[//]: # (python run_sweep.py --config experiments/{experiment_name}/sweep_config.json)

[//]: # (```)

[//]: # ()
[//]: # (Schedule multiple experiments:)

[//]: # (```bash)

[//]: # (python schedule.py --config experiments/{experiment_name}/model_config.json)

[//]: # (```)

[//]: # ()
[//]: # ()
[//]: # (### Experiments)

[//]: # ()
[//]: # (Each experiment is configured via two JSON files located in experiments/{experiment_name}/:)

[//]: # (- model_config.json â€” specifies encoder/decoder architecture, latent space priors, optimization parameters)

[//]: # (- data_config.json â€” defines the dataset source &#40;synthetic, medical, satellite&#41;, preprocessing, batch size, etc.)

[//]: # ()
[//]: # (Example fields in model_config.json:)

[//]: # ()
[//]: # (The `experiments/` directory contains JSON configuration files for models and datasets:)

[//]: # (- `model.json`: model architecture, prior type, latent dimension, etc.)

[//]: # (- `data.json`: dataset path, loader parameters)

[//]: # (- `sweep.json`: hyperparameter search grid)

[//]: # (```json)

[//]: # ({)

[//]: # (  "project": "isnmm",)

[//]: # (  "experiment": "lmm",)

[//]: # (  "model": "vasca",)

[//]: # (  "run_id": "run_name")

[//]: # (})

[//]: # (```)

[//]: # ()
[//]: # (---)

[//]: # ()
[//]: # (## ğŸ“Š Data)

[//]: # ()
[//]: # (The framework supports the following data sources:)

[//]: # (- Synthetic datasets for simulation &#40;ground-truth available&#41;)

[//]: # (- Public hyperspectral satellite images &#40;Urban, Cuprite, Samson&#41;)

[//]: # (- Anonymized DCE-MRI scans for medical imaging from public datasets)

[//]: # ()
[//]: # (Formats:)

[//]: # (- `.npy`, `.h5` for hyperspectral)

[//]: # (- `.nii`, `.nii.gz` for MRI)

[//]: # ()
[//]: # (Preprocessing steps include normalization, masking, and spatial augmentation.)

[//]: # ()
[//]: # (---)

[//]: # ()
[//]: # (## ğŸ“Š Results)

[//]: # ()
[//]: # (The model:)

[//]: # (- Achieves **~20% improvement** in parameter estimation vs. ICA/NMF)

[//]: # (- Trains **2Ã— faster** than unconstrained baselines)

[//]: # (- Recovers interpretable latent factors with **simplex constraints**)

[//]: # (- Provides **theoretical identifiability guarantees** for nonlinear mixing)

[//]: # ()
[//]: # ([//]: # &#40;The model achieves:&#41;)
[//]: # ()
[//]: # ([//]: # &#40;- ~20% improvement in latent parameter recovery over ICA/NMF&#41;)
[//]: # ()
[//]: # ([//]: # &#40;- 2Ã— faster training convergence with constrained latent space&#41;)
[//]: # ()
[//]: # ([//]: # &#40;- Improved interpretability and class separability&#41;)
[//]: # ()
[//]: # ([//]: # &#40;- Strong generalization to unseen imaging samples&#41;)
[//]: # ()
[//]: # ()
[//]: # (Key metrics:)

[//]: # (- RMSE, RÂ², ELBO)

[//]: # (- Residual Mutual Information)

[//]: # (- Amari Distance &#40;for latent subspace recovery&#41;)

[//]: # ()
[//]: # (---)

[//]: # ()
[//]: # (## ğŸ™ Acknowledgements)

[//]: # (This work is part of the master's thesis by Vladyslav Pauk under the supervision of Prof. Xiao Fu at Oregon State University.)
[//]: # ( Vladyslav Pauk**, in collaboration with **Prof. Xiao Fu** at **Oregon State University**.)

[//]: # ()
[//]: # (This rep...)

[//]: # ()
[//]: # (## ğŸ“„ Publication)

[//]: # ()
[//]: # (- **Master's Thesis**: "Deep Generative Modeling for Hyperspectral Imaging")

[//]: # (- **IEEE Preprint**: &#40;Coming Soon&#41;)

[//]: # (- **Slides**: [PDF/Google Slides Link])

[//]: # ()
[//]: # (---)

[//]: # ()
[//]: # (## ğŸ“š Citation)

[//]: # ()
[//]: # (If you use this code or method, please cite:)

[//]: # ()
[//]: # (```bibtex)

[//]: # (@misc{pauk2024generative,)

[//]: # (  author = {Vlad Pauk},)

[//]: # (  title = {Deep Generative Modeling for Hyperspectral \& Medical Imaging},)

[//]: # (  year = {2024},)

[//]: # (  note = {Master's Thesis, Oregon State University})

[//]: # (})

[//]: # (```)

[//]: # ()


[//]: # ()
[//]: # (## ğŸ“¬ Contact)

[//]: # ()
[//]: # (- **Author**: Dr. Vladyslav Pauk)

[//]: # (- **Email**: [vlad.paukv@oregonstate.edu]&#40;mailto:vlad.pauk@oregonstate.edu&#41;)

[//]: # (- **Website**: [https://linkedin.com/vladyslav-pauk]&#40;https://linkedin.com/vladyslav-pauk&#41;)

[//]: # ()
[//]: # (---)

[//]: # ()
[//]: # (## ğŸ”— References)

[//]: # ()
[//]: # (- HyvÃ¤rinen et al., â€œNonlinear ICA using auxiliary variables,â€ AISTATS 2019)

[//]: # (- Locatello et al., â€œDisentanglement Challenges,â€ ICML 2019)

[//]: # (- Miao & Qi, â€œSpectral Unmixing from Hyperspectral Imagery,â€ IEEE TGRS 2007)

[//]: # ()
[//]: # (---)
