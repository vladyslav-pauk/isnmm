# Deep Generative Modeling for Hyperspectral & Medical Imaging

## üß† Overview

This repository implements **NISCA** ‚Äî a modular deep generative framework for unsupervised source separation from high-dimensional imaging data such as **hyperspectral satellite images** and **dynamic contrast-enhanced MRI scans**. It leverages **variational autoencoders (VAEs)** with **geometric constraints** (e.g., simplex priors) and **post-nonlinear decoders** to recover interpretable latent factors under **nonlinear** and **noisy** mixing.

This work is part of the master's thesis by Vladyslav Pauk under the supervision of Prof. Xiao Fu at Oregon State University.

---

## üìÅ Repository Structure

```
.
‚îú‚îÄ‚îÄ experiments/              # Experiment folders with data/model config JSON files
‚îÇ   ‚îî‚îÄ‚îÄ {experiment}/
‚îÇ       ‚îî‚îÄ‚îÄ config/
‚îÇ           ‚îú‚îÄ‚îÄ data.json
‚îÇ           ‚îú‚îÄ‚îÄ model/
‚îÇ           ‚îÇ   ‚îî‚îÄ‚îÄ {model_name}.json
‚îÇ           ‚îî‚îÄ‚îÄ sweep/
‚îÇ               ‚îî‚îÄ‚îÄ {sweep_config}.json
‚îú‚îÄ‚îÄ model/                    # Main model definitions: NISCA, CNAE, VASCA, etc.
‚îÇ   ‚îú‚îÄ‚îÄ architectures/        # Encoder-decoder variants
‚îÇ   ‚îú‚îÄ‚îÄ config/               # Default model configuration JSONs
‚îÇ   ‚îú‚îÄ‚îÄ modules/              # LightningModule wrappers for training
‚îÇ   ‚îú‚îÄ‚îÄ benchmarks/           # MVES and other classic baselines
‚îÇ   ‚îî‚îÄ‚îÄ metric/               # Evaluation metrics (e.g., separation, identifiability)
‚îú‚îÄ‚îÄ modules/                  # Optimizer and transform libraries
‚îÇ   ‚îú‚îÄ‚îÄ optimizer/            # Augmented Lagrangian optimizer
‚îÇ   ‚îú‚îÄ‚îÄ network/              # CNN, FCN, KAN, positive linear layers
‚îÇ   ‚îî‚îÄ‚îÄ transform/            # Nonlinear transforms (logit, glogit, etc.)
‚îú‚îÄ‚îÄ data/                     # Data loaders: MRI, hyperspectral, synthetic, etc.
‚îÇ   ‚îú‚îÄ‚îÄ {domain}.py           # MRI, hyperspectral, astronomical, EEG, etc.
‚îÇ   ‚îú‚îÄ‚îÄ *.json                # Dataset configurations
‚îÇ   ‚îî‚îÄ‚îÄ plots/                # Diagnostic plots (MRI, tensor slices)
‚îú‚îÄ‚îÄ scripts/                  # High-level wrappers and analysis tools
‚îÇ   ‚îú‚îÄ‚îÄ run_dataset.py
‚îÇ   ‚îú‚îÄ‚îÄ run_sweep.py
‚îÇ   ‚îú‚îÄ‚îÄ analyze_sweep.py
‚îÇ   ‚îú‚îÄ‚îÄ explore_model.py
‚îÇ   ‚îî‚îÄ‚îÄ compare_models.py
‚îú‚îÄ‚îÄ helpers/                  # Training entrypoint and sweep orchestration
‚îÇ   ‚îú‚îÄ‚îÄ trainer.py            # Core train_model() function
‚îÇ   ‚îú‚îÄ‚îÄ generate_data.py      # Synthetic data simulation
‚îÇ   ‚îî‚îÄ‚îÄ sweep_runner.py       # Grid & random search over configs
‚îú‚îÄ‚îÄ utils/                    # Logging (W&B), metrics, plotting, config parsing
‚îÇ   ‚îú‚îÄ‚îÄ wandb_tools.py
‚îÇ   ‚îú‚îÄ‚îÄ plot_tools.py
‚îÇ   ‚îî‚îÄ‚îÄ config_tools.py
‚îî‚îÄ‚îÄ notebooks/                # Optional Jupyter notebooks for visualization
```

---

## üöÄ Getting Started

### Installation

> Requires Python 3.11+

```bash
pip install -r requirements.txt
```

Set up W&B credentials:
```bash
wandb login
```

---

## üîß Usage

### 1. Train a Model

```bash
python helpers/trainer.py --experiment simplex_recovery --model nisca
```

This reads configuration from:
- `experiments/simplex_recovery/config/data.json`
- `experiments/simplex_recovery/config/model/nisca.json`

Optional overrides (e.g., batch size):
```bash
python helpers/trainer.py --experiment simplex_recovery --model nisca --batch_size 256
```

---

### 2. Run a Sweep

```bash
python scripts/run_sweep.py --experiment simplex_recovery --sweep sweep/model-param.json
```

Sweep configs are stored under:
```
experiments/{experiment_name}/config/sweep/
```

---

### 3. Visualize Results

```bash
python scripts/analyze_sweep.py --experiment simplex_recovery
python scripts/explore_model.py --experiment simplex_recovery --model nisca
```

Plots and logs will be saved and logged to W&B under the specified experiment name.

---

## üìä Datasets

The framework supports:

- ‚úÖ Synthetic mixtures with known ground truth
- ‚úÖ Hyperspectral satellite images (Urban, Cuprite, Samson)
- ‚úÖ Public DCE-MRI volumes
- ‚úÖ Financial and astronomical data

All datasets are configured using `data.json` with preprocessing and loading logic defined in `data/*.py`.

---

## üß† Models

Implemented models include:

- `nisca`: Nonlinear ICA with simplex prior
- `vasca`: Variational simplex component analysis
- `cnae`: Constrained nonlinear autoencoder
- `nica`: Nonlinear ICA baseline
- `snae`: Simplex autoencoder
- `aevb`: Standard VAE (baseline)

Each model has its own encoder/decoder class under `model/architectures` and a training logic module in `model/modules`.

---

## üìè Metrics

The following metrics are supported:

- **Reconstruction error** (RMSE)
- **Subspace distance** (Amari distance, spectral angle)
- **Residual nonlinearity**
- **Simplex mismatch**
- **Constraint error**
- **PSNR** and **R¬≤**
- **Separation & identifiability**

All metrics are computed via `model/metric/*.py` and logged to W&B.

---

## üõ†Ô∏è Technological Stack

- **PyTorch Lightning** for training
- **Weights & Biases (W&B)** for logging
- **NumPy**, **Matplotlib**, **Scikit-learn**
- **Docker** + **GCP** compatibility
- **Configurable JSON experiments**
- Optional CUDA acceleration

---

## üìÑ Publication

- [**Master's Thesis**](https://github.com/vladyslav-pauk/isnmm/blob/master/docs/thesis.pdf): *Deep Generative Modeling for Hyperspectral & Medical Imaging*, Vladyslav Pauk, OSU (2024)
- **IEEE Preprint**: Coming soon, see draft [here](https://arxiv.org/abs/2401.00000)

---

## üìö Citation

```bibtex
@misc{pauk2024generative,
  author = {Vladyslav Pauk},
  title = {Deep Generative Modeling for Hyperspectral \& Medical Imaging},
  year = {2024},
  note = {Master's Thesis, Oregon State University}
}
```

---

## ü§ù Contact

- **Author**: Vladyslav Pauk  
- **Email**: [vlad.paukv@oregonstate.edu](mailto:vlad.paukv@oregonstate.edu)  
- **Website**: [linkedin.com/in/vladyslav-pauk](https://linkedin.com/in/vladyslav-pauk)

---





# Deep Generative Modeling for Hyperspectral & Medical Imaging

## Overview

This repository presents codebase, datasets, and documentation for NISCA, a scalable deep generative model designed to recover interpretable latent representations from high-dimensional imaging data. The model supports unsupervised source separation under nonlinear, noisy, and high-dimensional conditions‚Äîa setting common in medical imaging (DCE-MRI) and remote sensing (hyperspectral satellite images). 

[//]: # (This repository contains the codebase, datasets, and documentation for the project **"Deep Generative Modeling for Hyperspectral & Medical Imaging"** by **Dr. Vladyslav Pauk**, in collaboration with **Prof. Xiao Fu** at **Oregon State University**.)

[//]: # (The project focuses on developing a deep generative model for unsupervised tissue and material separation from high-dimensional imaging data such as **hyperspectral satellite images** and **DCE-MRI scans**. The approach extends **VASCA** using deep architecture, achieving interpretable and identifiable representations of mixed sources under nonlinear and noisy conditions.)

[//]: # (The project focuses on developing a deep generative model for hyperspectral and medical imaging data, specifically for unsupervised tissue and material separation. The model is based on a variational autoencoder &#40;VAE&#41; framework with geometric constraints, allowing for the identification of latent sources in high-dimensional data from satellite images and DCE-MRI scans.)

[//]: # (A scalable, interpretable latent variable model for unsupervised tissue and material separation from high-dimensional imaging data, including hyperspectral satellite images and DCE-MRI scans. This work extends post-nonlinear ICA using variational autoencoders &#40;VAEs&#41; with geometric constraints.)


Key features:
- Bayesian inference via deep variational autoencoders
- Geometrically constrained latent space (e.g., simplex priors) suitable for categorical ground truth
- Post-nonlinear decoder architecture
- Theoretical identifiability under nonlinear mixing
- Synthetic and real-world datasets (hyperspectral, DCE-MRI)
- Comprehensive experiment tracking with Weights & Biases
- Efficient implementation compatible with high-performance computing using CUDA
- Modular and scalable PyTorch Lightning pipeline
- Integrated support for GCP/Docker


For more information, see the Master thesis manuscript, IEEE preprint, or slides.


---

## üìÅ Contents

- [Code](#code)
- [Usage](#usage)
  - [Notebooks](#notebooks)
  - [Training module](#training-module)
  - [Scripts](#scripts)
  - [Experiments](#experiments)
- [Data](#data)
- [Results](#results)
- [Acknowledgements](#acknowledgements)
- [Publication](#publication)
- [Citation](#citation)
- [License](#license)
- [Contributing](#contributing)
- [Contact](#contact)
- [References](#references)
- [üõ†Ô∏è Technological Stack](#Ô∏ètechnological-stack)

---

## üíæ Code

The code implements the NISCA algorithm for training VAEs on imaging data using the PyTorch Lightning framework, as well benchmarking against linear baselines, and nonlinear benchmark. The code is modular and designed for scalability, allowing for easy experimentation with different model architectures and configurations.
It supports both hyperspectral and medical data formats, includes synthetic simulation pipelines, and uses structured experiment tracking.

The core codebase includes:
- Modular PyTorch Lightning modules for training, evaluation, and logging
- Configurable architecture for encoder, decoder, and latent space
- Experiment tracking via Weights & Biases (W&B)
- Dockerized environment for reproducibility

Root directory structure:
```
.
‚îú‚îÄ‚îÄ datasets/           # Data loading, preprocessing, simulation
‚îú‚îÄ‚îÄ docs/               # Documentation (Markdown)
‚îú‚îÄ‚îÄ experiments/        # Experiment config files (JSON)
‚îú‚îÄ‚îÄ notebooks/          # Analysis, visualization, diagnostics
‚îú‚îÄ‚îÄ src/                # Main source scripts and tools
```

```
### Experiment Structure

```text
.
‚îú‚îÄ‚îÄ experiments/                # Experiment configurations
‚îÇ   ‚îú‚îÄ‚îÄ vision/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ config/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ data.json
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ model/
‚îÇ   ‚îÇ           ‚îî‚îÄ‚îÄ aevb.json
‚îÇ   ‚îú‚îÄ‚îÄ fin_portfolio_return/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ yahoo.json
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ nisca.json
‚îÇ   ‚îî‚îÄ‚îÄ simplex_recovery/
‚îÇ       ‚îî‚îÄ‚îÄ config/
‚îÇ           ‚îú‚îÄ‚îÄ data.json
‚îÇ           ‚îú‚îÄ‚îÄ sweep/
‚îÇ           ‚îÇ   ‚îú‚îÄ‚îÄ model-param.json
‚îÇ           ‚îÇ   ‚îú‚îÄ‚îÄ single_run.json
‚îÇ           ‚îÇ   ‚îú‚îÄ‚îÄ model-snr.json
‚îÇ           ‚îÇ   ‚îî‚îÄ‚îÄ model-datasize.json
‚îÇ           ‚îî‚îÄ‚îÄ model/
‚îÇ               ‚îú‚îÄ‚îÄ nisca.json
‚îÇ               ‚îî‚îÄ‚îÄ vasca.json
‚îú‚îÄ‚îÄ wandb/                     # Weights & Biases run logs
‚îÇ   ‚îî‚îÄ‚îÄ run-*/                 # Each run with logs, files, and metadata
‚îÇ       ‚îú‚îÄ‚îÄ logs/
‚îÇ       ‚îú‚îÄ‚îÄ files/
‚îÇ       ‚îî‚îÄ‚îÄ tmp/
```

Source code structure:
```
‚îú‚îÄ‚îÄ src/                       # Main source scripts and tools
‚îÇ   ‚îú‚îÄ‚îÄ data_module.py
‚îÇ   ‚îú‚îÄ‚îÄ metrics_module.py
‚îÇ   ‚îú‚îÄ‚îÄ evaluate.py
‚îÇ   ‚îú‚îÄ‚îÄ schedule.py
‚îÇ   ‚îú‚îÄ‚îÄ SPA.py
‚îÇ   ‚îî‚îÄ‚îÄ test_prism.py
‚îú‚îÄ‚îÄ experiments/               # Experiment drivers
‚îÇ   ‚îú‚îÄ‚îÄ hyperspectral.py
‚îÇ   ‚îú‚îÄ‚îÄ mri.py
‚îÇ   ‚îú‚îÄ‚îÄ synthetic.py
‚îÇ   ‚îî‚îÄ‚îÄ portfolio.py
‚îú‚îÄ‚îÄ utils/                     # Utilities (logging, config, matrix ops)
‚îÇ   ‚îú‚îÄ‚îÄ config_tools.py
‚îÇ   ‚îú‚îÄ‚îÄ wandb_tools.py
‚îÇ   ‚îú‚îÄ‚îÄ matrix_tools.py
‚îÇ   ‚îú‚îÄ‚îÄ plot_tools.py
‚îÇ   ‚îî‚îÄ‚îÄ utils.py
‚îú‚îÄ‚îÄ image_marker/              # MRI marker web tool (Flask-based)
‚îÇ   ‚îú‚îÄ‚îÄ app.py
‚îÇ   ‚îú‚îÄ‚îÄ marked_pixels.mat
‚îÇ   ‚îî‚îÄ‚îÄ templates/
‚îÇ       ‚îî‚îÄ‚îÄ index.html
‚îú‚îÄ‚îÄ scripts/                   # Scripts for sweeping, evaluation, etc.
‚îÇ   ‚îú‚îÄ‚îÄ run_sweep.py
‚îÇ   ‚îú‚îÄ‚îÄ analyze_sweep.py
‚îÇ   ‚îú‚îÄ‚îÄ explore_model.py
‚îÇ   ‚îú‚îÄ‚îÄ compare_models.py
‚îÇ   ‚îî‚îÄ‚îÄ abundance_classifier.py
‚îú‚îÄ‚îÄ model/                     # Model architectures and configs
‚îÇ   ‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ snae.json
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ nisca.json
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ vasca.json
‚îÇ   ‚îú‚îÄ‚îÄ architectures/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ aevb.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ vasca.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ nisca.py
‚îÇ   ‚îú‚îÄ‚îÄ modules/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ lightning.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ae.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ vae.py
‚îÇ   ‚îî‚îÄ‚îÄ benchmarks/
‚îÇ       ‚îî‚îÄ‚îÄ mves.py
‚îú‚îÄ‚îÄ modules/                   # Modular components (networks, metrics, optimizers)
‚îÇ   ‚îú‚îÄ‚îÄ optimizer/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ augmented_lagrange.py
‚îÇ   ‚îú‚îÄ‚îÄ network/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fcn_constructor.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ linear_positive.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ vision.py
‚îÇ   ‚îú‚îÄ‚îÄ metric/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ separation.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ subspace_distance.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ residual_nonlinearity.py
‚îÇ   ‚îú‚îÄ‚îÄ distribution/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ standard.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mixture_model.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ location_scale.py
‚îÇ   ‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ hyperspectral.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dce_mri.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ synthetic.py
‚îÇ   ‚îî‚îÄ‚îÄ transform/
‚îÇ       ‚îú‚îÄ‚îÄ logit_transform.py
‚îÇ       ‚îú‚îÄ‚îÄ glogit_transform.py
‚îÇ       ‚îî‚îÄ‚îÄ nonlinear_component_wise.py
‚îú‚îÄ‚îÄ helpers/                   # Sweep & training helpers
‚îÇ   ‚îú‚îÄ‚îÄ generate_data.py
‚îÇ   ‚îú‚îÄ‚îÄ sweep_analyzer.py
‚îÇ   ‚îî‚îÄ‚îÄ trainer.py
```

---

## Installation

### Requirements

...

## üß™ Usage

### Notebooks

Explore interactive Jupyter notebooks covering a range of topics from training to model evaluation and visualization, as well as some experiments.
- Model training walkthrough
- Posterior sampling and latent space visualization
- Component-wise reconstruction
- Quantitative evaluation and benchmark comparisons

### Training Module
Run train.py to train a model with a specific config file.
```bash
python train.py --config experiments/{experiment_name}/model_config.json
```

### Scripts

Run a hyperparameter sweep:
```bash
python run_sweep.py --config experiments/{experiment_name}/sweep_config.json
```

Schedule multiple experiments:
```bash
python schedule.py --config experiments/{experiment_name}/model_config.json
```


### Experiments

Each experiment is configured via two JSON files located in experiments/{experiment_name}/:
- model_config.json ‚Äî specifies encoder/decoder architecture, latent space priors, optimization parameters
- data_config.json ‚Äî defines the dataset source (synthetic, medical, satellite), preprocessing, batch size, etc.

Example fields in model_config.json:

The `experiments/` directory contains JSON configuration files for models and datasets:
- `model.json`: model architecture, prior type, latent dimension, etc.
- `data.json`: dataset path, loader parameters
- `sweep.json`: hyperparameter search grid
```json
{
  "project": "isnmm",
  "experiment": "lmm",
  "model": "vasca",
  "run_id": "run_name"
}
```

---

## üìä Data

The framework supports the following data sources:
- Synthetic datasets for simulation (ground-truth available)
- Public hyperspectral satellite images (Urban, Cuprite, Samson)
- Anonymized DCE-MRI scans for medical imaging from public datasets

Formats:
- `.npy`, `.h5` for hyperspectral
- `.nii`, `.nii.gz` for MRI

Preprocessing steps include normalization, masking, and spatial augmentation.

---

## üìä Results

The model:
- Achieves **~20% improvement** in parameter estimation vs. ICA/NMF
- Trains **2√ó faster** than unconstrained baselines
- Recovers interpretable latent factors with **simplex constraints**
- Provides **theoretical identifiability guarantees** for nonlinear mixing

[//]: # (The model achieves:)

[//]: # (- ~20% improvement in latent parameter recovery over ICA/NMF)

[//]: # (- 2√ó faster training convergence with constrained latent space)

[//]: # (- Improved interpretability and class separability)

[//]: # (- Strong generalization to unseen imaging samples)


Key metrics:
- RMSE, R¬≤, ELBO
- Residual Mutual Information
- Amari Distance (for latent subspace recovery)

---

## üôè Acknowledgements

This rep...

## üìÑ Publication

- **Master's Thesis**: "Deep Generative Modeling for Hyperspectral Imaging"
- **IEEE Preprint**: (Coming Soon)
- **Slides**: [PDF/Google Slides Link]

---

## üìö Citation

If you use this code or method, please cite:

```bibtex
@misc{pauk2024generative,
  author = {Vlad Pauk},
  title = {Deep Generative Modeling for Hyperspectral \& Medical Imaging},
  year = {2024},
  note = {Master's Thesis, Oregon State University}
}
```

---

## üìù License

MIT License (see `LICENSE` file)

---

## üë• Contributing

Pull requests, feedback, and discussions are welcome. Please submit issues or suggestions via GitHub.

---

## üì¨ Contact

- **Author**: Dr. Vladyslav Pauk
- **Email**: [vlad.paukv@oregonstate.edu](mailto:vlad.pauk@oregonstate.edu)
- **Website**: [https://linkedin.com/vladyslav-pauk](https://linkedin.com/vladyslav-pauk)

---

## üîó References

- Hyv√§rinen et al., ‚ÄúNonlinear ICA using auxiliary variables,‚Äù AISTATS 2019
- Locatello et al., ‚ÄúDisentanglement Challenges,‚Äù ICML 2019
- Miao & Qi, ‚ÄúSpectral Unmixing from Hyperspectral Imagery,‚Äù IEEE TGRS 2007

---
